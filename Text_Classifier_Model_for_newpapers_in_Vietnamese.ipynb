{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classifier_Model_for_newpapers_in_Vietnamese.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NEDzEiyQJrsZ",
        "zIQYltEnDi89",
        "WwEgdVN-11MQ",
        "9drZ1lJG6oCa"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8KziexH3JKh"
      },
      "source": [
        "## ***Natual  Language Processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ_8jM0FXBTm"
      },
      "source": [
        "#**Introduction**\n",
        "1.   The goal: Implement Text Classifier Model for newpapers in Vietnamese.\n",
        "2.  Text Classification is an example of supervised machine learning task since a labelled dataset containing text documents and their labels is used for train a classifier. There are 4 steps that we need to do as follows: \n",
        "  *   Preprocessing Data: Data preparation, Feature Engineering\n",
        "  *   Model training\n",
        "  *   Improve Performance\n",
        "  *   Model evaluation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_u5s_-edQlF"
      },
      "source": [
        "# Preprocessing Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ2JCsVEnOo9"
      },
      "source": [
        "##Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaNgQ2JV9Nfb"
      },
      "source": [
        "Data was clone in here: https://github.com/duyvuleo/VNTC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaRsTjXS51O9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16eadb78-9126-4d81-f042-3dface51fff2"
      },
      "source": [
        "!pip3 install vncorenlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vncorenlp\n",
            "  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=7c8da8d763b6be3f182c5cdc885d4a7d38e43bc76a64d738e463bd57ce9ab166\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_OZICTt59Y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fadbd254-1c1e-4727-c13b-4ba7f35aee6e"
      },
      "source": [
        "!pip install gensim "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMEVpLBuh6rZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "036e51d1-b920-4984-af46-8a1f55f5178e"
      },
      "source": [
        "# To perform word segmentation only\n",
        "!wget 'https://github.com/vncorenlp/VnCoreNLP/archive/v1.1.1.zip' -O ./models.$$ && unzip -o ./models.$$ && rm -r ./models.$$."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-13 07:26:47--  https://github.com/vncorenlp/VnCoreNLP/archive/v1.1.1.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/vncorenlp/VnCoreNLP/zip/v1.1.1 [following]\n",
            "--2021-10-13 07:26:48--  https://codeload.github.com/vncorenlp/VnCoreNLP/zip/v1.1.1\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘./models.265’\n",
            "\n",
            "./models.265            [                <=> ] 137.29M  26.2MB/s    in 6.2s    \n",
            "\n",
            "2021-10-13 07:26:54 (22.1 MB/s) - ‘./models.265’ saved [143955573]\n",
            "\n",
            "Archive:  ./models.265\n",
            "3b5c2aac53bb1fda0502d89ab8085b712e299fab\n",
            "   creating: VnCoreNLP-1.1.1/\n",
            "  inflating: VnCoreNLP-1.1.1/LICENSE.md  \n",
            "  inflating: VnCoreNLP-1.1.1/Readme.md  \n",
            "  inflating: VnCoreNLP-1.1.1/TagsetDescription.md  \n",
            "  inflating: VnCoreNLP-1.1.1/VLSP2013_POS_tagset.pdf  \n",
            "  inflating: VnCoreNLP-1.1.1/VnCoreNLP-1.1.1.jar  \n",
            "  inflating: VnCoreNLP-1.1.1/VnDT-treebank-description.pdf  \n",
            "   creating: VnCoreNLP-1.1.1/models/\n",
            "   creating: VnCoreNLP-1.1.1/models/dep/\n",
            " extracting: VnCoreNLP-1.1.1/models/dep/vi-dep.xz  \n",
            "   creating: VnCoreNLP-1.1.1/models/ner/\n",
            " extracting: VnCoreNLP-1.1.1/models/ner/vi-500brownclusters.xz  \n",
            " extracting: VnCoreNLP-1.1.1/models/ner/vi-ner.xz  \n",
            " extracting: VnCoreNLP-1.1.1/models/ner/vi-pretrainedembeddings.xz  \n",
            "   creating: VnCoreNLP-1.1.1/models/postagger/\n",
            " extracting: VnCoreNLP-1.1.1/models/postagger/vi-tagger  \n",
            "   creating: VnCoreNLP-1.1.1/models/wordsegmenter/\n",
            "  inflating: VnCoreNLP-1.1.1/models/wordsegmenter/vi-vocab  \n",
            "  inflating: VnCoreNLP-1.1.1/models/wordsegmenter/wordsegmenter.rdr  \n",
            "  inflating: VnCoreNLP-1.1.1/pom.xml  \n",
            "   creating: VnCoreNLP-1.1.1/src/\n",
            "   creating: VnCoreNLP-1.1.1/src/main/\n",
            "   creating: VnCoreNLP-1.1.1/src/main/java/\n",
            "   creating: VnCoreNLP-1.1.1/src/main/java/vn/\n",
            "   creating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/\n",
            "   creating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/ner/\n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/ner/NerRecognizer.java  \n",
            "   creating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/parser/\n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/parser/DependencyParser.java  \n",
            "   creating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/postagger/\n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/postagger/PosTagger.java  \n",
            "   creating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/tokenizer/\n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/tokenizer/StringUtils.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/tokenizer/Tokenizer.java  \n",
            "   creating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/wordsegmenter/\n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/wordsegmenter/FWObject.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/wordsegmenter/Node.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/wordsegmenter/Utils.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/wordsegmenter/Vocabulary.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/wordsegmenter/WordSegmenter.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/corenlp/wordsegmenter/WordTag.java  \n",
            "   creating: VnCoreNLP-1.1.1/src/main/java/vn/pipeline/\n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/pipeline/Annotation.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/pipeline/LexicalInitializer.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/pipeline/Sentence.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/pipeline/Utils.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/pipeline/VnCoreNLP.java  \n",
            "  inflating: VnCoreNLP-1.1.1/src/main/java/vn/pipeline/Word.java  \n",
            "   creating: VnCoreNLP-1.1.1/src/main/resources/\n",
            "  inflating: VnCoreNLP-1.1.1/src/main/resources/log4j.properties  \n",
            "   creating: VnCoreNLP-1.1.1/src/test/\n",
            "   creating: VnCoreNLP-1.1.1/src/test/java/\n",
            "  inflating: VnCoreNLP-1.1.1/src/test/java/VnCoreNLPExample.java  \n",
            "rm: cannot remove './models.$.': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MioH7rZb4OR5"
      },
      "source": [
        "import numpy as np\n",
        "import gensim\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from vncorenlp import VnCoreNLP \n",
        "VNCOREDIR='/content/VnCoreNLP-1.1.1/VnCoreNLP-1.1.1.jar'\n",
        "ANNOTATOR=VnCoreNLP(VNCOREDIR,port=9000,annotators='wseg',quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "R0UgtfjTx0Ge",
        "outputId": "dfaaefb7-3c75-46db-cddb-135cde846c78"
      },
      "source": [
        "file_path='/content/drive/MyDrive/Data_VietnamNews/Train_Full'\n",
        "labels=[]\n",
        "count_file=[]\n",
        "for label in os.listdir(file_path):\n",
        "  files=os.listdir(os.path.join(file_path,label))\n",
        "  count_file.append(len(files))\n",
        "  labels.append(label)\n",
        "#Statisfical train data\n",
        "y_pos=np.arange(len(labels))\n",
        "plt.barh(y_pos,count_file,align='center')\n",
        "plt.yticks(y_pos,labels=labels)\n",
        "plt.title('Total texts in Train_data: %d' %(sum(count_file)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Fw14O0yB0Hfe",
        "outputId": "52aa196e-5990-4ffe-9a9e-768ef8786647"
      },
      "source": [
        "file_path='/content/drive/MyDrive/Data_VietnamNews/Test_Full'\n",
        "labels=[]\n",
        "count_file=[]\n",
        "for label in os.listdir(file_path):\n",
        "  files=os.listdir(os.path.join(file_path,label))\n",
        "  count_file.append(len(files))\n",
        "  labels.append(label)\n",
        "#Statisfical train data\n",
        "y_pos=np.arange(len(labels))\n",
        "plt.barh(y_pos,count_file,align='center')\n",
        "plt.yticks(y_pos,labels=labels)\n",
        "plt.title('Total texts in Test_data: %d' %(sum(count_file)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaplKXeBycTx"
      },
      "source": [
        "def normalization_text(text):\n",
        "  text = gensim.utils.simple_preprocess(text)\n",
        "  return ' '.join(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kVEojDOXex8"
      },
      "source": [
        "def vietnamese_tokenize(text):\n",
        "    words = ANNOTATOR.tokenize(text)\n",
        "    list_word=[]\n",
        "    for word in words:\n",
        "        list_word += word\n",
        "    return ' '.join(list_word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8t1c_vS6JGB"
      },
      "source": [
        "#Remove stopwords from corpus\n",
        "\n",
        "#Create list stopword\n",
        "file_path='/content/drive/MyDrive/DataTextClassification_VietnamNews/vietnamese-stopwords-dash.txt'\n",
        "dic_stopwords=[]\n",
        "with open(file_path,'r',encoding='utf-8') as f:\n",
        "  lines = f.readlines()\n",
        "for word in lines:\n",
        "  word=word[:-1]\n",
        "  dic_stopwords.append(word)\n",
        "dic_stopwords\n",
        "\n",
        "#Remove\n",
        "def remove_stopwords(line):\n",
        "    words = []\n",
        "    for word in line.strip().split():\n",
        "        if word not in dic_stopwords:\n",
        "            words.append(word)\n",
        "    return ' '.join(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY36mQ6koNW3"
      },
      "source": [
        "#Create function to read txt \n",
        "def get_txt(file_path):\n",
        "  with open(file_path,'r',encoding='utf-16') as f:\n",
        "    lines = f.readlines()\n",
        "    lines = ' '.join(lines)\n",
        "    lines = normalization_text(lines)\n",
        "    lines = vietnamese_tokenize(lines)\n",
        "    lines = remove_stopwords(lines)\n",
        "  return lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5JegQrQ_s4F",
        "outputId": "39f28c80-ecb8-40eb-a3cd-9fed1758d02c"
      },
      "source": [
        "#Read 1 sample in train data\n",
        "features=[]\n",
        "labels=[]\n",
        "file_path='/content/drive/MyDrive/Data_VietnamNews/Train_Full'\n",
        "label = os.listdir(file_path)[0]\n",
        "file=os.listdir(os.path.join(file_path,label))[0]\n",
        "features.append(get_txt(os.path.join(file_path,label,file)))\n",
        "features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nhà_khoa_học nhiễm hố chôn gà dịch kiến phản_ánh người_dân nhiễm chôn gà chết tp hcm hố chôn dịch trào thoát khí nặng_mùi hôm trời nóng_bức vnexpress trao_đổi nhà_khoa_học quản_lý môi_trường giáo_sư tiến_sĩ tưởng thị hội_giảng_viên viện khoa_học công_nghệ môi_trường đh bách_khoa hà_nội động_vật chôn sâu đất phân_huỷ dạng hiếu_khí yếm_khí hợp_chất dạng lỏng thể khí_các dịch lỏng phát_sinh ngấm đất nhiễm xảy nghĩa_trang văn điển hà_nội khí thành phân_huỷ chất_hữu_cơ ch nh co thoát môi_trường mùi hôi độc_hại môi_trường sống giáo_sư nguyễn_công mẫn phó chủ_tịch viện địa kỹ_thuật liên_hiệp hội khoa_học_kỹ_thuật việt_nam chất_hữu_cơ phân_huỷ bãi chôn lấp rác chứa hợp_chất hữu_cơ canxi xương hố chôn gà chết dịch chứa vi_trùng bệnh biện_pháp thích_hợp thông_thường hố chôn lấp đường thoát rác ngấm đất phát_tán môi_trường xung_quanh khả_năng nguy_cơ nhiễm nước_ngầm tuỳ_thuộc tính_chất địa_tầng kiểm_tra xét_nghiệm kết_quả chính_xác đoàn thị trưởng phòng quản_lý môi_trường sở tài_nguyên môi_trường tp hcm trung_tâm_tế dự_phòng tiến_hành mẫu chôn gà kết_quả chính_xác nguy_cơ nhiễm kỹ_thuật mẫu xét_nghiệm kết_quả hố chôn khô_ráo chôn quy_trình kỹ_thuật khả_năng nhiễm khu_vực huyện nhà_bè ngập kết_luận chính_xác nhiễm mặt giếng_khoan độ sâu hố chôn nguy_cơ nhiễm nước_ngầm xảy môi_trường đất chôn phát_hiện dấu_hiệu nhiễm trường_hợp người_dân phản_ánh mùi xú_uế phát_sinh hố chôn bình_thường phân_huỷ chất_hữu_cơ ngắn hiện_tượng trung_tâm_tế dự_phòng tiến_hành đắp đất rải vôi nhiễm giáo_sư hoàng thuỷ long trả_lời trực_tuyến dịch cúm chủ trại gà long_an chết bệnh cúm trường bán_trú tẩy_chay thịt gia_cầm chim cảnh mua_bán tp hcm phát_hiện dịch cúm_gà']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPiX5U5VNRoJ"
      },
      "source": [
        "GetData\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3nAZ3RBMy0w"
      },
      "source": [
        "#Loading text to list\n",
        "def get_data(file_path):\n",
        "  labels=[]\n",
        "  features=[]\n",
        "  for label in tqdm(os.listdir(file_path)):\n",
        "    files=os.listdir(os.path.join(file_path,label))\n",
        "    for file_name in files:\n",
        "      features.append(get_txt(os.path.join(file_path,label,file_name)))\n",
        "      labels.append(label)\n",
        "  return features,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYkW_Cf2HigU",
        "outputId": "abc812b2-5588-44c8-ef78-69073bb32f05"
      },
      "source": [
        "# Reading train data\n",
        "x,y=get_data('/content/drive/MyDrive/Data_VietnamNews/Train_Full')\n",
        "print(x[0])\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [13:12<00:00, 79.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nhà_khoa_học nhiễm hố chôn gà dịch kiến phản_ánh người_dân nhiễm chôn gà chết tp hcm hố chôn dịch trào thoát khí nặng_mùi hôm trời nóng_bức vnexpress trao_đổi nhà_khoa_học quản_lý môi_trường giáo_sư tiến_sĩ tưởng thị hội_giảng_viên viện khoa_học công_nghệ môi_trường đh bách_khoa hà_nội động_vật chôn sâu đất phân_huỷ dạng hiếu_khí yếm_khí hợp_chất dạng lỏng thể khí_các dịch lỏng phát_sinh ngấm đất nhiễm xảy nghĩa_trang văn điển hà_nội khí thành phân_huỷ chất_hữu_cơ ch nh co thoát môi_trường mùi hôi độc_hại môi_trường sống giáo_sư nguyễn_công mẫn phó chủ_tịch viện địa kỹ_thuật liên_hiệp hội khoa_học_kỹ_thuật việt_nam chất_hữu_cơ phân_huỷ bãi chôn lấp rác chứa hợp_chất hữu_cơ canxi xương hố chôn gà chết dịch chứa vi_trùng bệnh biện_pháp thích_hợp thông_thường hố chôn lấp đường thoát rác ngấm đất phát_tán môi_trường xung_quanh khả_năng nguy_cơ nhiễm nước_ngầm tuỳ_thuộc tính_chất địa_tầng kiểm_tra xét_nghiệm kết_quả chính_xác đoàn thị trưởng phòng quản_lý môi_trường sở tài_nguyên môi_trường tp hcm trung_tâm_tế dự_phòng tiến_hành mẫu chôn gà kết_quả chính_xác nguy_cơ nhiễm kỹ_thuật mẫu xét_nghiệm kết_quả hố chôn khô_ráo chôn quy_trình kỹ_thuật khả_năng nhiễm khu_vực huyện nhà_bè ngập kết_luận chính_xác nhiễm mặt giếng_khoan độ sâu hố chôn nguy_cơ nhiễm nước_ngầm xảy môi_trường đất chôn phát_hiện dấu_hiệu nhiễm trường_hợp người_dân phản_ánh mùi xú_uế phát_sinh hố chôn bình_thường phân_huỷ chất_hữu_cơ ngắn hiện_tượng trung_tâm_tế dự_phòng tiến_hành đắp đất rải vôi nhiễm giáo_sư hoàng thuỷ long trả_lời trực_tuyến dịch cúm chủ trại gà long_an chết bệnh cúm trường bán_trú tẩy_chay thịt gia_cầm chim cảnh mua_bán tp hcm phát_hiện dịch cúm_gà\n",
            "Chinh tri Xa hoi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvNKJMJskFPz"
      },
      "source": [
        "Convert data to .pkl, make it convenient to use next time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef1m9h0AIf5V"
      },
      "source": [
        "pickle.dump(x, open('/content/drive/MyDrive/Data_VietnamNews/X_data.pkl', 'wb'))\n",
        "pickle.dump(y, open('/content/drive/MyDrive/Data_VietnamNews/Y_data.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaBZIbN5Kigc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a62a928-29ea-4966-dee6-959881784922"
      },
      "source": [
        "# Similar to test data\n",
        "x_test,y_test=get_data('/content/drive/MyDrive/Data_VietnamNews/Test_Full')\n",
        "pickle.dump(x_test, open('/content/drive/MyDrive/Data_VietnamNews/X_test.pkl', 'wb'))\n",
        "pickle.dump(y_test, open('/content/drive/MyDrive/Data_VietnamNews/Y_test.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [20:39<00:00, 124.00s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmPoU6ogjR0Z"
      },
      "source": [
        "## Features Engineering\n",
        "* Convert data type text to vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFa9Mt6PtFlG"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TSVbmlrjhW-"
      },
      "source": [
        "X_data = pickle.load(open('/content/drive/MyDrive/Data_VietnamNews/X_data.pkl', 'rb'))\n",
        "Y_data = pickle.load(open('/content/drive/MyDrive/Data_VietnamNews/Y_data.pkl', 'rb'))\n",
        "\n",
        "X_test = pickle.load(open('/content/drive/MyDrive/Data_VietnamNews/X_test.pkl', 'rb'))\n",
        "Y_test = pickle.load(open('/content/drive/MyDrive/Data_VietnamNews/Y_test.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em6Hea6fo6fA"
      },
      "source": [
        "### Analyze data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC4CFTt4vkvR"
      },
      "source": [
        "import collections\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrw8dUzspNwR"
      },
      "source": [
        "X_length_corpus=list(map(lambda x: len(x.split(' ')),X_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnxUPh8Jwg_R"
      },
      "source": [
        "X_length_corpus=np.array(X_length_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rvs7wrfv7CY"
      },
      "source": [
        "occurrences = collections.Counter(X_length_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ57Y7xL-WsK",
        "outputId": "ef3631f8-d845-4c09-a18c-a8e13d2dc8db"
      },
      "source": [
        "np.array(list(occurrences.keys())).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "502.0406976744186"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B4XwOBv44dA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef08d42-e2d4-4525-ba00-5cc20f215608"
      },
      "source": [
        "occurrences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({10: 1,\n",
              "         12: 2,\n",
              "         13: 3,\n",
              "         15: 1,\n",
              "         16: 5,\n",
              "         17: 6,\n",
              "         18: 12,\n",
              "         19: 7,\n",
              "         20: 15,\n",
              "         21: 19,\n",
              "         22: 19,\n",
              "         23: 23,\n",
              "         24: 30,\n",
              "         25: 29,\n",
              "         26: 41,\n",
              "         27: 37,\n",
              "         28: 40,\n",
              "         29: 55,\n",
              "         30: 54,\n",
              "         31: 57,\n",
              "         32: 48,\n",
              "         33: 51,\n",
              "         34: 56,\n",
              "         35: 60,\n",
              "         36: 74,\n",
              "         37: 81,\n",
              "         38: 81,\n",
              "         39: 76,\n",
              "         40: 63,\n",
              "         41: 97,\n",
              "         42: 100,\n",
              "         43: 108,\n",
              "         44: 98,\n",
              "         45: 107,\n",
              "         46: 112,\n",
              "         47: 118,\n",
              "         48: 108,\n",
              "         49: 122,\n",
              "         50: 112,\n",
              "         51: 127,\n",
              "         52: 120,\n",
              "         53: 135,\n",
              "         54: 148,\n",
              "         55: 170,\n",
              "         56: 172,\n",
              "         57: 150,\n",
              "         58: 161,\n",
              "         59: 176,\n",
              "         60: 162,\n",
              "         61: 154,\n",
              "         62: 184,\n",
              "         63: 186,\n",
              "         64: 162,\n",
              "         65: 190,\n",
              "         66: 191,\n",
              "         67: 219,\n",
              "         68: 190,\n",
              "         69: 178,\n",
              "         70: 191,\n",
              "         71: 211,\n",
              "         72: 198,\n",
              "         73: 207,\n",
              "         74: 200,\n",
              "         75: 197,\n",
              "         76: 194,\n",
              "         77: 213,\n",
              "         78: 192,\n",
              "         79: 186,\n",
              "         80: 218,\n",
              "         81: 213,\n",
              "         82: 222,\n",
              "         83: 207,\n",
              "         84: 185,\n",
              "         85: 190,\n",
              "         86: 201,\n",
              "         87: 204,\n",
              "         88: 177,\n",
              "         89: 189,\n",
              "         90: 227,\n",
              "         91: 203,\n",
              "         92: 194,\n",
              "         93: 183,\n",
              "         94: 189,\n",
              "         95: 190,\n",
              "         96: 206,\n",
              "         97: 176,\n",
              "         98: 189,\n",
              "         99: 207,\n",
              "         100: 166,\n",
              "         101: 175,\n",
              "         102: 175,\n",
              "         103: 146,\n",
              "         104: 183,\n",
              "         105: 176,\n",
              "         106: 163,\n",
              "         107: 177,\n",
              "         108: 157,\n",
              "         109: 173,\n",
              "         110: 178,\n",
              "         111: 172,\n",
              "         112: 172,\n",
              "         113: 161,\n",
              "         114: 158,\n",
              "         115: 169,\n",
              "         116: 164,\n",
              "         117: 148,\n",
              "         118: 169,\n",
              "         119: 168,\n",
              "         120: 137,\n",
              "         121: 156,\n",
              "         122: 162,\n",
              "         123: 167,\n",
              "         124: 135,\n",
              "         125: 141,\n",
              "         126: 163,\n",
              "         127: 152,\n",
              "         128: 142,\n",
              "         129: 145,\n",
              "         130: 131,\n",
              "         131: 135,\n",
              "         132: 130,\n",
              "         133: 164,\n",
              "         134: 141,\n",
              "         135: 137,\n",
              "         136: 127,\n",
              "         137: 142,\n",
              "         138: 135,\n",
              "         139: 121,\n",
              "         140: 155,\n",
              "         141: 149,\n",
              "         142: 131,\n",
              "         143: 110,\n",
              "         144: 141,\n",
              "         145: 126,\n",
              "         146: 125,\n",
              "         147: 119,\n",
              "         148: 129,\n",
              "         149: 116,\n",
              "         150: 135,\n",
              "         151: 111,\n",
              "         152: 132,\n",
              "         153: 121,\n",
              "         154: 113,\n",
              "         155: 102,\n",
              "         156: 111,\n",
              "         157: 106,\n",
              "         158: 101,\n",
              "         159: 118,\n",
              "         160: 110,\n",
              "         161: 102,\n",
              "         162: 91,\n",
              "         163: 84,\n",
              "         164: 95,\n",
              "         165: 103,\n",
              "         166: 98,\n",
              "         167: 120,\n",
              "         168: 97,\n",
              "         169: 95,\n",
              "         170: 96,\n",
              "         171: 103,\n",
              "         172: 73,\n",
              "         173: 94,\n",
              "         174: 96,\n",
              "         175: 91,\n",
              "         176: 74,\n",
              "         177: 86,\n",
              "         178: 73,\n",
              "         179: 105,\n",
              "         180: 99,\n",
              "         181: 87,\n",
              "         182: 108,\n",
              "         183: 97,\n",
              "         184: 68,\n",
              "         185: 62,\n",
              "         186: 77,\n",
              "         187: 70,\n",
              "         188: 89,\n",
              "         189: 100,\n",
              "         190: 74,\n",
              "         191: 59,\n",
              "         192: 77,\n",
              "         193: 82,\n",
              "         194: 81,\n",
              "         195: 89,\n",
              "         196: 74,\n",
              "         197: 65,\n",
              "         198: 66,\n",
              "         199: 72,\n",
              "         200: 70,\n",
              "         201: 68,\n",
              "         202: 75,\n",
              "         203: 88,\n",
              "         204: 63,\n",
              "         205: 78,\n",
              "         206: 59,\n",
              "         207: 73,\n",
              "         208: 75,\n",
              "         209: 65,\n",
              "         210: 66,\n",
              "         211: 73,\n",
              "         212: 66,\n",
              "         213: 60,\n",
              "         214: 73,\n",
              "         215: 61,\n",
              "         216: 70,\n",
              "         217: 78,\n",
              "         218: 67,\n",
              "         219: 72,\n",
              "         220: 63,\n",
              "         221: 56,\n",
              "         222: 66,\n",
              "         223: 53,\n",
              "         224: 63,\n",
              "         225: 60,\n",
              "         226: 62,\n",
              "         227: 65,\n",
              "         228: 53,\n",
              "         229: 66,\n",
              "         230: 63,\n",
              "         231: 53,\n",
              "         232: 55,\n",
              "         233: 50,\n",
              "         234: 49,\n",
              "         235: 52,\n",
              "         236: 44,\n",
              "         237: 54,\n",
              "         238: 62,\n",
              "         239: 64,\n",
              "         240: 72,\n",
              "         241: 63,\n",
              "         242: 39,\n",
              "         243: 58,\n",
              "         244: 51,\n",
              "         245: 47,\n",
              "         246: 57,\n",
              "         247: 38,\n",
              "         248: 69,\n",
              "         249: 45,\n",
              "         250: 47,\n",
              "         251: 51,\n",
              "         252: 52,\n",
              "         253: 51,\n",
              "         254: 52,\n",
              "         255: 40,\n",
              "         256: 59,\n",
              "         257: 43,\n",
              "         258: 47,\n",
              "         259: 50,\n",
              "         260: 55,\n",
              "         261: 67,\n",
              "         262: 47,\n",
              "         263: 42,\n",
              "         264: 37,\n",
              "         265: 55,\n",
              "         266: 45,\n",
              "         267: 47,\n",
              "         268: 55,\n",
              "         269: 41,\n",
              "         270: 52,\n",
              "         271: 38,\n",
              "         272: 45,\n",
              "         273: 45,\n",
              "         274: 38,\n",
              "         275: 41,\n",
              "         276: 38,\n",
              "         277: 38,\n",
              "         278: 45,\n",
              "         279: 42,\n",
              "         280: 36,\n",
              "         281: 53,\n",
              "         282: 33,\n",
              "         283: 58,\n",
              "         284: 42,\n",
              "         285: 23,\n",
              "         286: 40,\n",
              "         287: 40,\n",
              "         288: 35,\n",
              "         289: 35,\n",
              "         290: 43,\n",
              "         291: 47,\n",
              "         292: 36,\n",
              "         293: 37,\n",
              "         294: 29,\n",
              "         295: 34,\n",
              "         296: 38,\n",
              "         297: 29,\n",
              "         298: 43,\n",
              "         299: 42,\n",
              "         300: 29,\n",
              "         301: 34,\n",
              "         302: 35,\n",
              "         303: 39,\n",
              "         304: 34,\n",
              "         305: 46,\n",
              "         306: 28,\n",
              "         307: 27,\n",
              "         308: 36,\n",
              "         309: 23,\n",
              "         310: 38,\n",
              "         311: 33,\n",
              "         312: 32,\n",
              "         313: 39,\n",
              "         314: 24,\n",
              "         315: 20,\n",
              "         316: 29,\n",
              "         317: 28,\n",
              "         318: 31,\n",
              "         319: 35,\n",
              "         320: 34,\n",
              "         321: 20,\n",
              "         322: 31,\n",
              "         323: 37,\n",
              "         324: 31,\n",
              "         325: 27,\n",
              "         326: 30,\n",
              "         327: 36,\n",
              "         328: 39,\n",
              "         329: 28,\n",
              "         330: 29,\n",
              "         331: 29,\n",
              "         332: 34,\n",
              "         333: 36,\n",
              "         334: 25,\n",
              "         335: 22,\n",
              "         336: 25,\n",
              "         337: 22,\n",
              "         338: 24,\n",
              "         339: 30,\n",
              "         340: 26,\n",
              "         341: 23,\n",
              "         342: 26,\n",
              "         343: 30,\n",
              "         344: 31,\n",
              "         345: 27,\n",
              "         346: 32,\n",
              "         347: 30,\n",
              "         348: 27,\n",
              "         349: 22,\n",
              "         350: 27,\n",
              "         351: 22,\n",
              "         352: 30,\n",
              "         353: 27,\n",
              "         354: 29,\n",
              "         355: 23,\n",
              "         356: 29,\n",
              "         357: 23,\n",
              "         358: 23,\n",
              "         359: 25,\n",
              "         360: 23,\n",
              "         361: 20,\n",
              "         362: 27,\n",
              "         363: 24,\n",
              "         364: 26,\n",
              "         365: 33,\n",
              "         366: 24,\n",
              "         367: 25,\n",
              "         368: 16,\n",
              "         369: 26,\n",
              "         370: 19,\n",
              "         371: 26,\n",
              "         372: 9,\n",
              "         373: 20,\n",
              "         374: 22,\n",
              "         375: 27,\n",
              "         376: 22,\n",
              "         377: 12,\n",
              "         378: 20,\n",
              "         379: 21,\n",
              "         380: 25,\n",
              "         381: 14,\n",
              "         382: 27,\n",
              "         383: 26,\n",
              "         384: 19,\n",
              "         385: 25,\n",
              "         386: 21,\n",
              "         387: 13,\n",
              "         388: 21,\n",
              "         389: 20,\n",
              "         390: 17,\n",
              "         391: 23,\n",
              "         392: 18,\n",
              "         393: 15,\n",
              "         394: 17,\n",
              "         395: 14,\n",
              "         396: 18,\n",
              "         397: 17,\n",
              "         398: 16,\n",
              "         399: 24,\n",
              "         400: 16,\n",
              "         401: 22,\n",
              "         402: 15,\n",
              "         403: 18,\n",
              "         404: 22,\n",
              "         405: 19,\n",
              "         406: 13,\n",
              "         407: 23,\n",
              "         408: 18,\n",
              "         409: 17,\n",
              "         410: 20,\n",
              "         411: 14,\n",
              "         412: 11,\n",
              "         413: 23,\n",
              "         414: 20,\n",
              "         415: 17,\n",
              "         416: 13,\n",
              "         417: 18,\n",
              "         418: 19,\n",
              "         419: 9,\n",
              "         420: 16,\n",
              "         421: 15,\n",
              "         422: 18,\n",
              "         423: 15,\n",
              "         424: 18,\n",
              "         425: 15,\n",
              "         426: 8,\n",
              "         427: 14,\n",
              "         428: 11,\n",
              "         429: 14,\n",
              "         430: 22,\n",
              "         431: 18,\n",
              "         432: 9,\n",
              "         433: 17,\n",
              "         434: 13,\n",
              "         435: 14,\n",
              "         436: 12,\n",
              "         437: 11,\n",
              "         438: 9,\n",
              "         439: 8,\n",
              "         440: 14,\n",
              "         441: 14,\n",
              "         442: 14,\n",
              "         443: 12,\n",
              "         444: 11,\n",
              "         445: 14,\n",
              "         446: 14,\n",
              "         447: 8,\n",
              "         448: 9,\n",
              "         449: 17,\n",
              "         450: 11,\n",
              "         451: 15,\n",
              "         452: 9,\n",
              "         453: 5,\n",
              "         454: 7,\n",
              "         455: 11,\n",
              "         456: 18,\n",
              "         457: 23,\n",
              "         458: 11,\n",
              "         459: 8,\n",
              "         460: 8,\n",
              "         461: 7,\n",
              "         462: 11,\n",
              "         463: 16,\n",
              "         464: 12,\n",
              "         465: 10,\n",
              "         466: 8,\n",
              "         467: 15,\n",
              "         468: 12,\n",
              "         469: 12,\n",
              "         470: 12,\n",
              "         471: 15,\n",
              "         472: 7,\n",
              "         473: 11,\n",
              "         474: 11,\n",
              "         475: 10,\n",
              "         476: 4,\n",
              "         477: 12,\n",
              "         478: 7,\n",
              "         479: 9,\n",
              "         480: 10,\n",
              "         481: 10,\n",
              "         482: 12,\n",
              "         483: 15,\n",
              "         484: 9,\n",
              "         485: 10,\n",
              "         486: 5,\n",
              "         487: 14,\n",
              "         488: 7,\n",
              "         489: 19,\n",
              "         490: 8,\n",
              "         491: 9,\n",
              "         492: 5,\n",
              "         493: 11,\n",
              "         494: 9,\n",
              "         495: 8,\n",
              "         496: 5,\n",
              "         497: 4,\n",
              "         498: 11,\n",
              "         499: 10,\n",
              "         500: 3,\n",
              "         501: 9,\n",
              "         502: 10,\n",
              "         503: 10,\n",
              "         504: 10,\n",
              "         505: 4,\n",
              "         506: 4,\n",
              "         507: 10,\n",
              "         508: 11,\n",
              "         509: 10,\n",
              "         510: 6,\n",
              "         511: 6,\n",
              "         512: 12,\n",
              "         513: 13,\n",
              "         514: 10,\n",
              "         515: 4,\n",
              "         516: 12,\n",
              "         517: 3,\n",
              "         518: 4,\n",
              "         519: 9,\n",
              "         520: 6,\n",
              "         521: 7,\n",
              "         522: 8,\n",
              "         523: 6,\n",
              "         524: 7,\n",
              "         525: 9,\n",
              "         526: 4,\n",
              "         527: 7,\n",
              "         528: 8,\n",
              "         529: 6,\n",
              "         530: 6,\n",
              "         531: 5,\n",
              "         532: 11,\n",
              "         533: 4,\n",
              "         534: 7,\n",
              "         535: 7,\n",
              "         536: 9,\n",
              "         537: 8,\n",
              "         538: 7,\n",
              "         539: 8,\n",
              "         540: 6,\n",
              "         541: 6,\n",
              "         542: 8,\n",
              "         543: 1,\n",
              "         544: 10,\n",
              "         545: 5,\n",
              "         546: 7,\n",
              "         547: 4,\n",
              "         548: 8,\n",
              "         549: 2,\n",
              "         550: 5,\n",
              "         551: 11,\n",
              "         552: 1,\n",
              "         553: 7,\n",
              "         554: 2,\n",
              "         555: 5,\n",
              "         556: 3,\n",
              "         557: 8,\n",
              "         558: 7,\n",
              "         559: 5,\n",
              "         560: 7,\n",
              "         561: 6,\n",
              "         562: 4,\n",
              "         563: 9,\n",
              "         564: 2,\n",
              "         565: 6,\n",
              "         566: 4,\n",
              "         567: 6,\n",
              "         568: 4,\n",
              "         569: 10,\n",
              "         570: 5,\n",
              "         571: 3,\n",
              "         572: 2,\n",
              "         573: 5,\n",
              "         574: 12,\n",
              "         575: 5,\n",
              "         576: 5,\n",
              "         577: 4,\n",
              "         578: 4,\n",
              "         579: 5,\n",
              "         580: 7,\n",
              "         581: 7,\n",
              "         582: 8,\n",
              "         583: 3,\n",
              "         584: 6,\n",
              "         585: 5,\n",
              "         586: 2,\n",
              "         587: 3,\n",
              "         588: 5,\n",
              "         589: 8,\n",
              "         590: 4,\n",
              "         591: 6,\n",
              "         592: 7,\n",
              "         593: 6,\n",
              "         594: 2,\n",
              "         595: 4,\n",
              "         597: 5,\n",
              "         598: 5,\n",
              "         599: 8,\n",
              "         600: 7,\n",
              "         601: 5,\n",
              "         602: 4,\n",
              "         603: 9,\n",
              "         604: 7,\n",
              "         605: 4,\n",
              "         606: 3,\n",
              "         607: 8,\n",
              "         608: 6,\n",
              "         609: 4,\n",
              "         610: 4,\n",
              "         611: 5,\n",
              "         612: 5,\n",
              "         613: 7,\n",
              "         614: 4,\n",
              "         615: 3,\n",
              "         616: 4,\n",
              "         617: 5,\n",
              "         618: 4,\n",
              "         619: 6,\n",
              "         620: 2,\n",
              "         621: 2,\n",
              "         622: 2,\n",
              "         623: 5,\n",
              "         624: 4,\n",
              "         625: 7,\n",
              "         626: 6,\n",
              "         627: 7,\n",
              "         628: 1,\n",
              "         629: 2,\n",
              "         630: 1,\n",
              "         631: 2,\n",
              "         632: 3,\n",
              "         633: 6,\n",
              "         634: 2,\n",
              "         635: 3,\n",
              "         636: 4,\n",
              "         637: 5,\n",
              "         638: 3,\n",
              "         639: 3,\n",
              "         640: 1,\n",
              "         641: 3,\n",
              "         642: 1,\n",
              "         643: 4,\n",
              "         644: 4,\n",
              "         645: 3,\n",
              "         646: 5,\n",
              "         647: 3,\n",
              "         648: 5,\n",
              "         649: 5,\n",
              "         650: 4,\n",
              "         651: 1,\n",
              "         652: 1,\n",
              "         653: 5,\n",
              "         654: 6,\n",
              "         655: 3,\n",
              "         656: 2,\n",
              "         657: 4,\n",
              "         658: 1,\n",
              "         659: 2,\n",
              "         660: 3,\n",
              "         661: 3,\n",
              "         662: 3,\n",
              "         663: 4,\n",
              "         664: 4,\n",
              "         665: 3,\n",
              "         666: 5,\n",
              "         667: 2,\n",
              "         668: 4,\n",
              "         669: 3,\n",
              "         670: 4,\n",
              "         671: 3,\n",
              "         672: 3,\n",
              "         673: 4,\n",
              "         674: 1,\n",
              "         675: 4,\n",
              "         676: 1,\n",
              "         677: 4,\n",
              "         678: 4,\n",
              "         679: 3,\n",
              "         680: 6,\n",
              "         681: 2,\n",
              "         682: 4,\n",
              "         683: 3,\n",
              "         684: 1,\n",
              "         686: 1,\n",
              "         687: 3,\n",
              "         688: 1,\n",
              "         689: 1,\n",
              "         690: 2,\n",
              "         691: 2,\n",
              "         692: 3,\n",
              "         693: 1,\n",
              "         694: 2,\n",
              "         695: 3,\n",
              "         697: 1,\n",
              "         698: 1,\n",
              "         699: 3,\n",
              "         700: 1,\n",
              "         701: 1,\n",
              "         703: 2,\n",
              "         704: 5,\n",
              "         705: 3,\n",
              "         707: 1,\n",
              "         708: 2,\n",
              "         709: 2,\n",
              "         710: 1,\n",
              "         711: 1,\n",
              "         712: 2,\n",
              "         714: 2,\n",
              "         715: 5,\n",
              "         716: 3,\n",
              "         718: 1,\n",
              "         719: 3,\n",
              "         720: 1,\n",
              "         721: 2,\n",
              "         723: 5,\n",
              "         724: 1,\n",
              "         725: 2,\n",
              "         726: 3,\n",
              "         727: 4,\n",
              "         729: 1,\n",
              "         731: 1,\n",
              "         732: 1,\n",
              "         734: 3,\n",
              "         735: 2,\n",
              "         736: 5,\n",
              "         737: 1,\n",
              "         738: 2,\n",
              "         739: 1,\n",
              "         740: 3,\n",
              "         742: 6,\n",
              "         744: 1,\n",
              "         745: 1,\n",
              "         747: 1,\n",
              "         748: 1,\n",
              "         749: 2,\n",
              "         750: 1,\n",
              "         753: 1,\n",
              "         754: 2,\n",
              "         757: 2,\n",
              "         758: 1,\n",
              "         759: 1,\n",
              "         760: 3,\n",
              "         761: 2,\n",
              "         762: 1,\n",
              "         763: 1,\n",
              "         764: 3,\n",
              "         766: 1,\n",
              "         768: 1,\n",
              "         769: 3,\n",
              "         770: 1,\n",
              "         773: 3,\n",
              "         775: 1,\n",
              "         776: 1,\n",
              "         779: 2,\n",
              "         782: 1,\n",
              "         784: 1,\n",
              "         786: 1,\n",
              "         788: 1,\n",
              "         789: 2,\n",
              "         791: 1,\n",
              "         795: 4,\n",
              "         796: 1,\n",
              "         798: 1,\n",
              "         799: 1,\n",
              "         800: 1,\n",
              "         801: 2,\n",
              "         802: 2,\n",
              "         803: 1,\n",
              "         806: 2,\n",
              "         810: 2,\n",
              "         811: 2,\n",
              "         812: 2,\n",
              "         816: 2,\n",
              "         819: 1,\n",
              "         821: 1,\n",
              "         823: 2,\n",
              "         826: 1,\n",
              "         827: 1,\n",
              "         831: 1,\n",
              "         833: 1,\n",
              "         834: 1,\n",
              "         835: 2,\n",
              "         837: 1,\n",
              "         838: 1,\n",
              "         841: 2,\n",
              "         843: 1,\n",
              "         845: 1,\n",
              "         846: 2,\n",
              "         847: 1,\n",
              "         850: 1,\n",
              "         856: 1,\n",
              "         861: 1,\n",
              "         864: 2,\n",
              "         865: 1,\n",
              "         870: 1,\n",
              "         873: 1,\n",
              "         874: 1,\n",
              "         880: 1,\n",
              "         883: 1,\n",
              "         886: 1,\n",
              "         889: 1,\n",
              "         890: 1,\n",
              "         891: 1,\n",
              "         899: 2,\n",
              "         904: 2,\n",
              "         915: 1,\n",
              "         918: 2,\n",
              "         923: 2,\n",
              "         927: 1,\n",
              "         931: 1,\n",
              "         937: 1,\n",
              "         939: 1,\n",
              "         940: 1,\n",
              "         944: 2,\n",
              "         946: 1,\n",
              "         954: 1,\n",
              "         957: 1,\n",
              "         959: 1,\n",
              "         964: 1,\n",
              "         965: 1,\n",
              "         974: 1,\n",
              "         977: 1,\n",
              "         978: 1,\n",
              "         979: 1,\n",
              "         986: 1,\n",
              "         990: 1,\n",
              "         996: 2,\n",
              "         1013: 1,\n",
              "         1020: 2,\n",
              "         1026: 1,\n",
              "         1028: 1,\n",
              "         1042: 1,\n",
              "         1056: 1,\n",
              "         1067: 1,\n",
              "         1094: 1,\n",
              "         1110: 1,\n",
              "         1111: 1,\n",
              "         1116: 1,\n",
              "         1137: 1,\n",
              "         1147: 1,\n",
              "         1190: 1,\n",
              "         1209: 1,\n",
              "         1216: 1,\n",
              "         1233: 1,\n",
              "         1239: 1,\n",
              "         1269: 1,\n",
              "         1287: 2,\n",
              "         1305: 1,\n",
              "         1306: 1,\n",
              "         1340: 1,\n",
              "         1354: 1,\n",
              "         1452: 1,\n",
              "         1480: 1,\n",
              "         1507: 1,\n",
              "         1509: 1,\n",
              "         1582: 1,\n",
              "         1645: 1,\n",
              "         1675: 1,\n",
              "         1679: 1,\n",
              "         1733: 1,\n",
              "         2020: 1,\n",
              "         2338: 1,\n",
              "         2574: 1,\n",
              "         2694: 1,\n",
              "         3212: 1,\n",
              "         3695: 1,\n",
              "         3965: 1,\n",
              "         4076: 1,\n",
              "         4405: 1,\n",
              "         5653: 1,\n",
              "         6033: 1})"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwha7gon6dWf"
      },
      "source": [
        "Nhận thấy có nhiều văn bản lớn hơn ~1000 kí tự lại rất ít nhưng xuất hiện ít lần, có vẻ ảnh hưởng gì đó. (Kết luận k ảnh hưởng gì tới kết quả)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ligbb7-Q-puu"
      },
      "source": [
        "for index in range(len(X_length_corpus)):\n",
        "  if X_length_corpus[index]>1000:\n",
        "    index_greater_than_1000_words.append(index);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbgHSVHGEwLe"
      },
      "source": [
        "index_greater_than_1000_words=[]\n",
        "for i,corpus in enumerate(X_data):\n",
        "  if (len(corpus.split(' '))<10):\n",
        "    index_greater_than_1000_words.append(i);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "GnxQ_eoPJQWm",
        "outputId": "b0febab5-4533-43eb-8270-ed20841298b5"
      },
      "source": [
        "X_data[i]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'góc hẹp sát bàn góc cây_xanh nâng góc vườn um_tùm cảm_giác xanh mát hiện quy_hoạch phố chừa trống vai_trò sân tác_dụng thông_thoáng tổ_chức đường thoát hố_ga tuỳ trang_trí sân thông_thường sân hai khuất tầm chức_năng phụ đồng_hồ nước_máy bơm dụng_cụ vệ_sinh sàn lộ_thiên trang_trí cây_xanh góc vườn bồn hẹp tận_dụng vách quanh treo giỏ hoa bò leo tường cây_xanh bàn_ghế ngoài_trời hóng gió đơn_giản băng ghế chỗ trò_chuyện đọc sách_báo trang_trí chất_liệu ốp tường đá sỏi gỗ gốm mảng màu_sắc gợi_mở thiên_nhiên trang_trí chảy vách ốp đá giả thác đổ hồ cột đá phun tổng_hợp yếu_tố khéo diện_tích hẹp tham chi_tiết vật_liệu gây_rối chật_chội chính_yếu góc cảm_giác rộng_mở dễ_chịu ghế bàn sân hóng mát sỏi đá tre góc thiên_nhiên thu diện_tích hẹp băng ghế đá đi tường mảng đá_ong bình gốm góc vạt cây_xanh lu kỷ_niệm hiện_đại thú_vị chủ_nhân'"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnZaA1Tl_oWe"
      },
      "source": [
        "for i in range(len(index_greater_than_1000_words)):\n",
        "  np.delete(X_data,index_greater_than_1000_words)\n",
        "  np.delete(Y_data,index_greater_than_1000_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOkDobH9DrOv",
        "outputId": "4f9749ac-4118-4ad9-a2bd-b38284982a12"
      },
      "source": [
        "len(X_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33759"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZcddUTIDtwm",
        "outputId": "aabad4d8-04ee-46c9-ca72-e32505f6b464"
      },
      "source": [
        "len(Y_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33759"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knrxe2uRcUEB"
      },
      "source": [
        "###Count mode\n",
        "\n",
        "  >-Some way you can do:\n",
        "* Count Vectorizer\n",
        "* TF-IDF (Term Frequency — Inverse Document Frequency)\n",
        "* Word Embedding\n",
        "* ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKR-RkoFJE-m"
      },
      "source": [
        "Thử giảm dictionary xuống 30000 từ vựng:\n",
        "* với countvect giảm hiệu quả\n",
        "* với tfidf: tăng hiệu quả với mô hình MultinomialNB, không ảnh hưởng SVM\n",
        "\n",
        "Thử giảm dictionary xuống 50000 từ vựng(không ảnh hưởng nhiều)\n",
        "\n",
        "Thử giảm dictionary xuống 20000 từ vựng(không ảnh hưởng nhiều)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Thử loại bỏ từ với tfidf:\n",
        "\n",
        "* min_df=3 (tăng 1 xíu) 0.02% :))\n",
        "* max_df=0.5 (vẫn thế)\n",
        "* max_df=0.5,min_df=50 (co kha nang)\n",
        "* min_df=10\n",
        "---\n",
        "Dùng n_gram: (1,2) tức là vocab sẽ có 1 từ hiện tại và 1 từ hiện tại + từ tiếp (rất khả quan)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWctvG_E9TuT"
      },
      "source": [
        "* max_df is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\".\n",
        "* min_df is used for removing terms that appear too infrequently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwGkCh1AIije"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRc60gtehiRR"
      },
      "source": [
        "####Count Vectorizer (AKA One-Hot Encoding):\n",
        "  * The idea is super simple. Create a vector that has as many dimensions as your corpora has unique words (dictionary). Each unique word has a unique dimension and will be represented by a 1 in that dimension with 0 everywhere else"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxxjju0ewWud"
      },
      "source": [
        "#Convert a collection of text documents to a matrix of token counts\n",
        "\n",
        "####\n",
        "#Create Count Vectorizer Object\n",
        "vectorizer = CountVectorizer(encoding='utf-8',analyzer='word',min_df=10,max_features=20000,ngram_range=(1,2))\n",
        "model=vectorizer.fit(X_data)\n",
        "#Save model vectorizer\n",
        "pickle.dump(model, open(os.path.join('/content/drive/MyDrive/Model_VietnameseNewsClassification', \"vectorizer_model.pkl\"), 'wb'))\n",
        "\n",
        "#Transform data\n",
        "X_data_countvec=vectorizer.transform(X_data)\n",
        "X_test_countvec=vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gpkKG_vL1jW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "832637f9-51b9-4bfc-da37-f85c7f18fdf0"
      },
      "source": [
        "print(X_data_countvec.shape)\n",
        "print(X_test_countvec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33759, 20000)\n",
            "(50373, 20000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_yvdto5hhjh"
      },
      "source": [
        "####TF-IDF (Term Frequency - Inverse Document Frequency):\n",
        "* In simpler terms, words that occur a lot but everywhere should be given very little weighting or significance\n",
        "* TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
        "* IDF(t) = log(Total number of documents / Number of documents with term t in it)\n",
        "* tf-idf(t, d) = tf(t, d) * log(N/(df + 1))\n",
        "\n",
        "With 3 level:\n",
        "* Word\n",
        "* N-gram\n",
        "* Char"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPuwvkRiF9fm"
      },
      "source": [
        "#TF-IDF\n",
        "####\n",
        "# Create TF-IDF Object\n",
        "vectorizer = TfidfVectorizer(encoding='utf-8',analyzer='word',min_df=10,max_features=20000,ngram_range=(1,2))\n",
        "model=vectorizer.fit(X_data)\n",
        "#Save model vectorized\n",
        "pickle.dump(model, open(os.path.join('/content/drive/MyDrive/Model_VietnameseNewsClassification', \"vectorizer_model_tfidf.pkl\"), 'wb'))\n",
        "\n",
        "#Transform data\n",
        "X_data_tfidf=vectorizer.transform(X_data)\n",
        "X_test_tfidf=vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvsi8z3Msu0p",
        "outputId": "281122bd-7f17-4cae-e594-188f9f1d5909"
      },
      "source": [
        "print(X_data_tfidf.shape)\n",
        "print(X_test_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33759, 20000)\n",
            "(50373, 20000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEDzEiyQJrsZ"
      },
      "source": [
        "####Word Embedding\n",
        "Detail: https://forum.machinelearningcoban.com/t/hoc-bieu-dien-ngon-ngu-cho-may-tinh/299\n",
        "* CBOW\n",
        "* Skip - gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F23MoDXksuZJ"
      },
      "source": [
        "# from gensim.models import KeyedVectors\n",
        "# from gensim.test.utils import datapath\n",
        "# from keras.preprocessing import sequence\n",
        "# word2vec_model_path=\"/content/drive/MyDrive/DataTextClassification_VietnamNews/baomoi.vn.model.bin\"\n",
        "# #Load Model trained on Vietnamese Wiki\n",
        "# w2v = KeyedVectors.load_word2vec_format(datapath(word2vec_model_path), binary=True,encoding='utf8')\n",
        "# vocab = w2v.vocab\n",
        "# wv=w2v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blcqZOZYqUYO"
      },
      "source": [
        "# #To get intersect my vocab and model vocab\n",
        "# def intersect_word2vec_data(X):\n",
        "#   word2vec_data=[]\n",
        "#   for x in X:\n",
        "#     text = []\n",
        "#     count=1\n",
        "#     for word in x.split(\" \"):\n",
        "#       if (word in vocab):\n",
        "#         text.append(wv[word])\n",
        "#     word2vec_data.append(text)\n",
        "#   return word2vec_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ymIeYlmtYye"
      },
      "source": [
        "# #Each word \n",
        "# X_data_w2v = intersect_word2vec_data(X_data)\n",
        "# X_test_w2v = intersect_word2vec_data(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5WL6SGwDQeN",
        "outputId": "08be970b-8dc2-4c2d-ff8b-220534895511"
      },
      "source": [
        "# len(df_data[0][2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIQYltEnDi89"
      },
      "source": [
        "##Encode label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaaZOaCjFtVG"
      },
      "source": [
        "#Create LabeblEncoder Object\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(Y_data)\n",
        "\n",
        "#Tranform label\n",
        "Y_data = le.transform(Y_data)\n",
        "Y_test = le.transform(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4iIGtaaL1gE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491f9273-cd90-4287-fc13-440bf16c5681"
      },
      "source": [
        "print(Y_data.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33759,)\n",
            "(50373,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwEgdVN-11MQ"
      },
      "source": [
        "# Model Training\n",
        "I apply:\n",
        "  * Navie Bayes\n",
        "  * Logistic Regression\n",
        "  * SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmjZt5y0_G7Q"
      },
      "source": [
        "Performance Measures:\n",
        "* Accuracy - Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations\n",
        "* Precision - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations\n",
        "* Recall (Sensitivity) - Recall is the ratio of correctly predicted positive observations to the all observations in actual class\n",
        "* F1 score - F1 Score is the weighted average of Precision and Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kReksasU14Mh"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7yuC0iorScI"
      },
      "source": [
        "def train_model(classifier,X_train,Y_train):\n",
        "  x_train, x_val, y_train, y_val = train_test_split(X_train,Y_train, test_size=0.2, random_state=42)\n",
        "  classifier.fit(x_train, y_train)\n",
        "\n",
        "  train_predictions = classifier.predict(x_train)\n",
        "  train_accuracy=accuracy_score(train_predictions, y_train)\n",
        "\n",
        "  y_predict = classifier.predict(x_val)\n",
        "  accuracy=accuracy_score(y_val,y_predict)\n",
        "  precision_micro=precision_score(y_val,y_predict,average='micro')\n",
        "  precision_macro=precision_score(y_val,y_predict,average='macro')\n",
        "  recall_micro=recall_score(y_val,y_predict,average='micro')\n",
        "  recall_macro=recall_score(y_val,y_predict,average='macro')\n",
        "  f1_micro=f1_score(y_val,y_predict,average='micro')\n",
        "  f1_macro=f1_score(y_val,y_predict,average='macro')\n",
        "  return classifier,train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFV4c8NmfRbW"
      },
      "source": [
        "def makeTable1(score):\n",
        "  value=[]\n",
        "  for i in score:\n",
        "    value.append(\"{:.3%}\".format(i))\n",
        "    \n",
        "  print('------------------------------------')\n",
        "  print('evaluation\\t\\tvalue')\n",
        "  print('------------------------------------')\n",
        "  print('train_accuracy\\t\\t',value[0],'\\n')\n",
        "  print('accuracy\\t\\t',value[1],'\\n')\n",
        "  print('precision_micro\\t\\t',value[2])\n",
        "  print('precision_macro\\t\\t',value[3])\n",
        "  print('recall_micro\\t\\t',value[4])\n",
        "  print('recall_macro\\t\\t',value[5])\n",
        "  print('f1_micro\\t\\t',value[6])\n",
        "  print('f1_macro\\t\\t',value[7])\n",
        "  print('------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmSsq7DTILqi"
      },
      "source": [
        "Model_path='/content/drive/MyDrive/Model_VietnameseNewsClassification'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6lDDihe5mNr"
      },
      "source": [
        "##Train by countvector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeWuGKJ8rSYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc34b5f-64ea-4599-ee6f-ffe806494c3e"
      },
      "source": [
        "#MultinomialNB  alpha=0.009\n",
        "scores=[]\n",
        "classifier,train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro=train_model(MultinomialNB(alpha=0.009),X_data_countvec,Y_data)\n",
        "pickle.dump(classifier, open(os.path.join(Model_path, \"countvec_MultinomialNB_model.pkl\"), 'wb'))\n",
        "scores.append([train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro])\n",
        "makeTable1(scores[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "train_accuracy\t\t 91.247% \n",
            "\n",
            "accuracy\t\t 88.655% \n",
            "\n",
            "precision_micro\t\t 88.655%\n",
            "precision_macro\t\t 88.655%\n",
            "recall_micro\t\t 88.655%\n",
            "recall_macro\t\t 88.713%\n",
            "f1_micro\t\t 88.655%\n",
            "f1_macro\t\t 88.272%\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wpT70WfDGqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6efd70db-bf43-4cb2-9c99-0c78ee6a6006"
      },
      "source": [
        "#LogisticRegression\n",
        "scores=[]\n",
        "classifier,train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro=train_model(LogisticRegression(random_state=0),X_data_countvec,Y_data)\n",
        "pickle.dump(classifier, open(os.path.join(Model_path, \"countvec_LogisticRegression_model.pkl\"), 'wb'))\n",
        "scores.append([train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro])\n",
        "makeTable1(scores[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "train_accuracy\t\t 99.878% \n",
            "\n",
            "accuracy\t\t 90.595% \n",
            "\n",
            "precision_micro\t\t 90.595%\n",
            "precision_macro\t\t 90.595%\n",
            "recall_micro\t\t 90.595%\n",
            "recall_macro\t\t 90.221%\n",
            "f1_micro\t\t 90.595%\n",
            "f1_macro\t\t 90.426%\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxb_0p3Hnrzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1830ff7-bde8-43d6-90ce-0b6133144551"
      },
      "source": [
        "#SVM \n",
        "scores=[]\n",
        "classifier,train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro=train_model(svm.LinearSVC(C=0.001),X_data_countvec,Y_data)\n",
        "pickle.dump(classifier, open(os.path.join(Model_path, \"countvec_SVM_model.pkl\"), 'wb'))\n",
        "scores.append([train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro])\n",
        "makeTable1(scores[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "train_accuracy\t\t 99.874% \n",
            "\n",
            "accuracy\t\t 89.603% \n",
            "\n",
            "precision_micro\t\t 89.603%\n",
            "precision_macro\t\t 89.603%\n",
            "recall_micro\t\t 89.603%\n",
            "recall_macro\t\t 89.021%\n",
            "f1_micro\t\t 89.603%\n",
            "f1_macro\t\t 89.273%\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GyC0GPN_GPs"
      },
      "source": [
        "##Train by tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BXMDFd35qqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d18573-d95c-4e87-e0f7-d21c56e98ef5"
      },
      "source": [
        "#MultinomialNB\n",
        "scores=[]\n",
        "classifier,train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro=train_model(MultinomialNB(alpha=0.004),X_data_tfidf,Y_data)\n",
        "scores.append([train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro])\n",
        "pickle.dump(classifier, open(os.path.join(Model_path, \"tfidf_MultinomialNB_model.pkl\"), 'wb'))\n",
        "makeTable1(scores[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "train_accuracy\t\t 93.602% \n",
            "\n",
            "accuracy\t\t 89.336% \n",
            "\n",
            "precision_micro\t\t 89.336%\n",
            "precision_macro\t\t 89.336%\n",
            "recall_micro\t\t 89.336%\n",
            "recall_macro\t\t 88.709%\n",
            "f1_micro\t\t 89.336%\n",
            "f1_macro\t\t 88.909%\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVjsk7uQBFD"
      },
      "source": [
        "Train accuracy:  0.956574543084807"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pps5OwJVXCuJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMhby9ioDSSl",
        "outputId": "1ac4b1f5-22d6-4c30-bc5e-ace456e12d0b"
      },
      "source": [
        "#LogisticRegression\n",
        "scores=[]\n",
        "####random_state=0,C=5,tol=0.01,class_weight='balanced'\n",
        "classifier,train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro=train_model(LogisticRegression(random_state=0,C=5,tol=0.01,class_weight='balanced'),X_data_tfidf,Y_data)\n",
        "scores.append([train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro])\n",
        "pickle.dump(classifier, open(os.path.join(Model_path, \"tfidf_LogisticRegression_model.pkl\"), 'wb'))\n",
        "makeTable1(scores[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "train_accuracy\t\t 95.827% \n",
            "\n",
            "accuracy\t\t 90.951% \n",
            "\n",
            "precision_micro\t\t 90.951%\n",
            "precision_macro\t\t 90.951%\n",
            "recall_micro\t\t 90.951%\n",
            "recall_macro\t\t 90.256%\n",
            "f1_micro\t\t 90.951%\n",
            "f1_macro\t\t 90.653%\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr2PiQQTAZL1"
      },
      "source": [
        "C tăng model train càng fit\n",
        "\n",
        "* Best choise: class_weight='balanced',C=0.5,tol=0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCGUyN6F6M5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f4a642-eacd-4a93-edfd-c4a09213d111"
      },
      "source": [
        "#SVM\n",
        "scores=[]\n",
        "####class_weight='balanced',C=0.5,tol=0.1\n",
        "classifier,train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro=train_model(svm.LinearSVC(class_weight='balanced',C=0.5,tol=0.1),X_data_tfidf,Y_data) \n",
        "scores.append([train_accuracy,accuracy,precision_micro,precision_micro,recall_micro,recall_macro,f1_micro,f1_macro])\n",
        "pickle.dump(classifier, open(os.path.join(Model_path, \"tfidf_SVM_model.pkl\"), 'wb'))\n",
        "makeTable1(scores[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "train_accuracy\t\t 98.393% \n",
            "\n",
            "accuracy\t\t 91.854% \n",
            "\n",
            "precision_micro\t\t 91.854%\n",
            "precision_macro\t\t 91.854%\n",
            "recall_micro\t\t 91.854%\n",
            "recall_macro\t\t 91.684%\n",
            "f1_micro\t\t 91.854%\n",
            "f1_macro\t\t 91.632%\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9drZ1lJG6oCa"
      },
      "source": [
        "##Train by Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21E4BA9T7kxB"
      },
      "source": [
        "# #MultinomialNB\n",
        "# classifier,train_accuracy=train_model(MultinomialNB(),X_data_w2v,Y_data)\n",
        "# pickle.dump(model, open(os.path.join(Model_path, \"w2v_MultinomialNB_model.pkl\"), 'wb'))\n",
        "# print(\"Train accuracy: \", train_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFpMBZWo7kub"
      },
      "source": [
        "# #Model không tốt lắm\n",
        "# #DecisionTreeClassifier\n",
        "# classifier,train_accuracy=train_model(tree.DecisionTreeClassifier(),X_data_w2v,Y_data)\n",
        "# pickle.dump(model, open(os.path.join(Model_path, \"w2v_DecisionTreeClassifier_model.pkl\"), 'wb'))\n",
        "# print(\"Train accuracy: \", train_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEyYOj7L7kfK"
      },
      "source": [
        "# #SVM\n",
        "# classifier,train_accuracy=train_model(svm.SVC(),X_data_w2v,Y_data)\n",
        "# pickle.dump(model, open(os.path.join(Model_path, \"w2v_SVM_model.pkl\"), 'wb'))\n",
        "# print(\"Train accuracy: \", train_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL5ydP4Dl73Z"
      },
      "source": [
        "#Improve Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhcJzM4BmAK4"
      },
      "source": [
        "Redo :\n",
        "1. Analyze data\n",
        "2. Feature engineering\n",
        "3. Model tuning\n",
        "4. Training, evaluate, argumentative\n",
        "5. Base on result, analyze, find the way to improve model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziebVJLUCyzO"
      },
      "source": [
        "GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwZ7KU8dCyIu"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7F65m6vSIct"
      },
      "source": [
        "# defining parameter range\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] ,\n",
        "              'tol': [1, 0.1, 0.01, 0.001, 0.0001]};\n",
        "# x_train, x_val, y_train, y_val = train_test_split(X_data_tfidf,Y_data, test_size=0.2, random_state=42)\n",
        "Model_path='/content/drive/MyDrive/Model_VietnameseNewsClassification'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOt3aCg9erFd",
        "outputId": "eaf20b45-3800-40ba-da7b-74e68772ba4b"
      },
      "source": [
        "clf = svm.LinearSVC(class_weight='balanced')\n",
        "grid = GridSearchCV(clf,param_grid,verbose=1).fit(X_data_tfidf,Y_data)\n",
        "pickle.dump(grid, open(os.path.join(Model_path, \"SVMgrid.pkl\"), 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done 175 out of 175 | elapsed: 13.1min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5nqnyR9oAss"
      },
      "source": [
        "SVMgrid = pickle.load(open('/content/drive/MyDrive/Model_VietnameseNewsClassification/SVMgrid.pkl','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yAlDzlGvphA",
        "outputId": "5cb05c3e-1efd-43e8-dc8f-2514c601dbbe"
      },
      "source": [
        "SVMgrid.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1, 'tol': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMrMyvmapKjH",
        "outputId": "20acdc55-53ba-41d2-9415-b38608030c5d"
      },
      "source": [
        "clf = LogisticRegression(random_state=0,class_weight='balanced')\n",
        "grid = GridSearchCV(clf,param_grid,verbose=1).fit(X_data_tfidf,Y_data)\n",
        "pickle.dump(grid, open(os.path.join(Model_path, \"LogisticReggrid.pkl\"), 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "[Parallel(n_jobs=1)]: Done 175 out of 175 | elapsed: 42.0min finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DwuhGQB8WJA"
      },
      "source": [
        "LogisticReggrid = pickle.load(open('/content/drive/MyDrive/Model_VietnameseNewsClassification/LogisticReggrid.pkl','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1CNBxGm8egV",
        "outputId": "6201568b-77d3-4f8b-d9a9-c046a6d7f70a"
      },
      "source": [
        "LogisticReggrid.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'tol': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBDYmem9gBTI"
      },
      "source": [
        "#Model evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5NZbqMMNnj4"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skw5zmBt7Evh"
      },
      "source": [
        "def evaluate_model(model_trained_path,X_test,Y_test):\n",
        "  model = pickle.load(open(model_trained_path, 'rb'))\n",
        "  Y_predict = model.predict(X_test)\n",
        "\n",
        "  accuracy=accuracy_score(Y_test,Y_predict)\n",
        "  precision_micro=precision_score(Y_test,Y_predict,average='micro')\n",
        "  precision_macro=precision_score(Y_test,Y_predict,average='macro')\n",
        "  f1_micro=f1_score(Y_test,Y_predict,average='micro')\n",
        "  f1_macro=f1_score(Y_test,Y_predict,average='macro')\n",
        "  return accuracy,precision_micro,precision_micro,f1_micro,f1_macro"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI2-9789JtIB"
      },
      "source": [
        "def makeTable(score):\n",
        "  value=[]\n",
        "  for i in score:\n",
        "    value.append(\"{:.3%}\".format(i))\n",
        "    \n",
        "  print('------------------------------------')\n",
        "  print('evaluation\\t\\tvalue')\n",
        "  print('------------------------------------')\n",
        "  print('accuracy\\t\\t',value[0],'\\n')\n",
        "  print('precision_micro\\t\\t',value[1])\n",
        "  print('precision_macro\\t\\t',value[2])\n",
        "  print('f1_micro\\t\\t',value[3])\n",
        "  print('f1_macro\\t\\t',value[4])\n",
        "  print('------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_h9NeavmPLg"
      },
      "source": [
        "##Evaluate with tfidf mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnpI1L_QmTn-",
        "outputId": "743e81a4-2277-4a1b-af80-46dfc108209b"
      },
      "source": [
        "model_trained_path=\"/content/drive/MyDrive/Model_VietnameseNewsClassification/tfidf_MultinomialNB_model.pkl\"\n",
        "score=[]\n",
        "score=evaluate_model(model_trained_path,X_test=X_test_tfidf,Y_test=Y_test)\n",
        "makeTable(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "accuracy\t\t 90.147% \n",
            "\n",
            "precision_micro\t\t 90.147%\n",
            "precision_macro\t\t 90.147%\n",
            "f1_micro\t\t 90.147%\n",
            "f1_macro\t\t 88.059%\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSYwus6nGoHE",
        "outputId": "15d769e7-6758-42ca-b4a8-395d86ee622c"
      },
      "source": [
        "model_trained_path=\"/content/drive/MyDrive/Model_VietnameseNewsClassification/tfidf_LogisticRegression_model.pkl\"\n",
        "score=[]\n",
        "score=evaluate_model(model_trained_path,X_test=X_test_tfidf,Y_test=Y_test)\n",
        "makeTable(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "accuracy\t\t 92.319% \n",
            "\n",
            "precision_micro\t\t 92.319%\n",
            "precision_macro\t\t 92.319%\n",
            "recall_micro\t\t 92.319%\n",
            "recall_macro\t\t 90.508%\n",
            "f1_micro\t\t 92.319%\n",
            "f1_macro\t\t 90.570%\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW8K_anmmTiW"
      },
      "source": [
        "# #Model không tốt lắm\n",
        "# model_trained_path=\"/content/drive/MyDrive/Model_VietnameseNewsClassification/tfidf_DecisionTreeClassifier_model.pkl\"\n",
        "# score=[]\n",
        "# score=evaluate_model(model_trained_path,X_test=X_test_countvec,Y_test=Y_test)\n",
        "# makeTable(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBnzLQigQ6Lv",
        "outputId": "c42f19f2-3140-4fb4-c122-abf567a68b09"
      },
      "source": [
        "model_trained_path=\"/content/drive/MyDrive/Model_VietnameseNewsClassification/tfidf_SVM_model.pkl\"\n",
        "score=[]\n",
        "score=evaluate_model(model_trained_path,X_test=X_test_tfidf,Y_test=Y_test)\n",
        "makeTable(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "accuracy\t\t 92.131% \n",
            "\n",
            "precision_micro\t\t 92.131%\n",
            "precision_macro\t\t 92.131%\n",
            "recall_micro\t\t 92.131%\n",
            "recall_macro\t\t 89.959%\n",
            "f1_micro\t\t 92.131%\n",
            "f1_macro\t\t 90.195%\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axTaBOGRmKnG"
      },
      "source": [
        "##Evaluate with countvec mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viGhtcaWmBj9",
        "outputId": "9e0d2ffa-eccf-45ef-a737-6caf9824896a"
      },
      "source": [
        "model_trained_path=\"/content/drive/MyDrive/Model_VietnameseNewsClassification/countvec_MultinomialNB_model.pkl\"\n",
        "score=[]\n",
        "score=evaluate_model(model_trained_path,X_test=X_test_countvec,Y_test=Y_test)\n",
        "makeTable(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "accuracy\t\t 89.816% \n",
            "\n",
            "precision_micro\t\t 89.816%\n",
            "precision_macro\t\t 89.816%\n",
            "f1_micro\t\t 89.816%\n",
            "f1_macro\t\t 87.889%\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FndjhztrGZp_",
        "outputId": "fc802ffc-1743-4252-b10d-5bbc62f6659a"
      },
      "source": [
        "model_trained_path=\"/content/drive/MyDrive/Model_VietnameseNewsClassification/countvec_LogisticRegression_model.pkl\"\n",
        "score=[]\n",
        "score=evaluate_model(model_trained_path,X_test=X_test_countvec,Y_test=Y_test)\n",
        "makeTable(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "accuracy\t\t 90.832% \n",
            "\n",
            "precision_micro\t\t 90.832%\n",
            "precision_macro\t\t 90.832%\n",
            "recall_micro\t\t 90.832%\n",
            "recall_macro\t\t 88.229%\n",
            "f1_micro\t\t 90.832%\n",
            "f1_macro\t\t 88.501%\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-tKNnzsk68Y",
        "outputId": "bb252aab-546f-4df9-da12-f53367938851"
      },
      "source": [
        "model_trained_path=\"/content/drive/MyDrive/Model_VietnameseNewsClassification/countvec_SVM_model.pkl\"\n",
        "score=[]\n",
        "score=evaluate_model(model_trained_path,X_test=X_test_countvec,Y_test=Y_test)\n",
        "makeTable(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "evaluation\t\tvalue\n",
            "------------------------------------\n",
            "accuracy\t\t 91.829% \n",
            "\n",
            "precision_micro\t\t 91.829%\n",
            "precision_macro\t\t 91.829%\n",
            "f1_micro\t\t 91.829%\n",
            "f1_macro\t\t 89.829%\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E1a2mVlQ683"
      },
      "source": [
        "#Application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGQMMWf9yPgA"
      },
      "source": [
        "\"\"\"args: \n",
        "    model: apply model to use\n",
        "    texts(array): any texts in vietnamese news\n",
        "  returns: predicts class of news\n",
        "\"\"\"\n",
        "def predict_news(ModelTrained_path,VectorizerModel_path,texts):\n",
        "  data=[]\n",
        "  labels=['Chính trị Xã hội', 'Đời sống', 'Khoa học', 'Kinh doanh',\n",
        "       'Pháp luật', 'Sức khỏe', 'Thế giới', 'Thể thao', 'Văn hóa',\n",
        "       'Vi tính']\n",
        "  for text in texts:\n",
        "    text = normalization_text(text)\n",
        "    text = vietnamese_tokenize(text)\n",
        "    text = remove_stopwords(text)\n",
        "    data.append(text)\n",
        "  \n",
        "  vectorizer = pickle.load(open(VectorizerModel_path, 'rb'))\n",
        "  #Transform data\n",
        "  data=vectorizer.transform(data)\n",
        "\n",
        "  #Model\n",
        "  model = pickle.load(open(ModelTrained_path, 'rb'))\n",
        "\n",
        "  #Predict\n",
        "  results=model.predict(data)\n",
        "  predicts=[labels[index] for index in results]\n",
        "\n",
        "  return predicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU_EKXqS0Jh1"
      },
      "source": [
        "Dữ liệu thực tế lấy ở VnExpress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU7XkUhVPGgm"
      },
      "source": [
        "texts = [\"\"\"\n",
        "  Phố bắp nướng Phố bắp nướng (đường Trường Sơn, quận Tân Bình-TPHCM) Ảnh: B.Trung Những đôi tình nhân ghé vào, vừa ăn vừa trò chuyện, có bếp lửa về khuya thêm phần lãng mạn. Tại TPHCM, những hàng bắp nướng vẫn thường xuất hiện ở một vài điểm trên các đường phố.\n",
        "Nhưng gần đây, những người bán bắp nướng đã tụ tập ở cuối đường Trường Sơn, quận Tân Bình, gần sân bay Tân Sơn Nhất để làm ăn. \n",
        "“Phố tình” sinh...“phố bắp” \n",
        "Khoảng 20 giờ là lúc phố bắp nướng đỏ lửa. Các chủ hàng vội vàng bày đồ nghề ra vỉa hè. Than được quạt lên, bắp được lôi từ trong bao ra xâu vào những que tre nhỏ đặt lên bếp. Cạnh bên là các tấm biển viết nguệch ngoạc “bắp nướng”, “bắp xào”. Những người bán hàng tay quạt, tay thoăn thoắt trở bắp, mặt ướt đẫm mồ hôi. Chị Thanh, quê Quảng Ngãi, cho hay mỗi ngày chị đi chợ Hóc Môn chọn những trái bắp ngon nhất về bóc sẵn vỏ để đấy, tối lại đem ra phố này nướng. Chị bảo, bắp nướng ngon thì phải là bắp nếp. Để chiều lòng khách, chị luôn mua bắp non lẫn bắp già cho khách dễ bề chọn lựa. Các hàng bắp nướng còn có thêm một chiếc chảo nhỏ, chai mỡ, ít tôm khô để sẵn sàng đáp ứng khi khách gọi món bắp xào. Chị Nga, ở Củ Chi, cho biết thêm vào mùa mưa bắp nướng mới dễ bán. Dường như không khí mát mẻ, se lạnh vào ban đêm khiến khách chuộng ăn bắp nướng hơn hẳn. \n",
        "Đường Trường Sơn lâu nay vẫn được giới trẻ gọi là “phố tình yêu”. Các cặp tình nhân đến đây tranh thủ những khoảng tối trên lề đường để tâm sự. Thật ra, những người bán bắp nướng đã nhanh nhảu phát hiện được nơi tụ tập của các đôi bạn trẻ ở đây, nên tìm tới bày bán. Từ khi có các hàng bắp nướng, những đôi tình nhân ghé vào, vừa ngồi ăn vừa nói chuyện và có bếp sưởi ấm khi trời trở gió về khuya, xem ra càng thêm phần lãng mạn. 21 giờ, phố tình cũng như phố bắp nướng bắt đầu nhộn nhịp. Tấp xe máy vào vỉa hè, các vị khách- đa phần là thanh niên - hào hứng sà đến bếp nướng bắp. Trong lúc chờ bắp chín, họ tranh thủ trò chuyệân. Càng về khuya khách càng đông. Các chủ hàng nhanh tay quạt lửa, nhiều khi phải có người phụ thêm. Có nhóm bạn trẻ đi trên những chiếc xe rất thời trang, ăn mặc đẹp, “tập kích” vào một hàng bắp nướng, lập tức góc phố này trở nên ồn ào bởi tiếng cười đùa. \n",
        "Làm ăn tạm bợ \n",
        "Phần lớn những người làm nghề bán bắp nướng ở đây là dân nghèo ngoại tỉnh. Ban ngày họ làm những công việc khác nhau, ban đêm mang bắp ra đây bán để kiếm thêm thu nhập. Chị Thanh cho biết, chị phải thuê nhà 600.000 đồng/ tháng. Ban ngày chồng làm phụ hồ còn chị bán trái cây dạo. Tiền bán bắp nướng cũng đủ trả chi phí ở trọ. Giá một trái bắp nướng là 3.000 đồng. Trung bình mỗi đêm chị Thanh bán được khoảng 40 trái bắp, lời được vài ba chục ngàn đồng. \n",
        "Sau 24 giờ, khi đường phố đã vắng người qua lại, những người bán bắp nướng cũng lục tục về nhà. Vất vả cực nhọc, họ lại luôn nơm nớp lo âu. Dạo này sân bay Tân Sơn Nhất đang mở rộng và xây dựng lại nên họ mới có cơ hội “đậu” ở khu này. Một mai khi xây dựng xong, chắc chắn các hàng bắp nướng ở đây sẽ bị “hốt”. Tuy họ làm ăn lương thiện, nhưng đường phố này lại là cửa ngõ TP, nơi gây ấn tượng đầu tiên cho du khách khi xuống sân bay, nên xem ra nghề bán bắp nướng ở đây chỉ tạm bợ ngày nào hay ngày đó. Phố bắp nướng với khói, rác, chủ khách ngồi, đứng trên vỉa hè tạo nên cảnh lộn xộn, dơ bẩn, không văn minh chút nào. Chị Nga nói, nhiều đôi tình nhân không ngại âu yếm nhau dưới bóng đèn đường. Lại có không ít nhóm thanh niên mang theo cả rượu kéo đến, nheo nhéo đòi nướng bắp thật nhanh để làm thức nhấm, rồi ngồi nhậu tại chỗ... \n",
        "\n",
        "\"\"\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0xFM85WziF6"
      },
      "source": [
        "Predict with tfidf LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lctofSSFyN3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcb5861-7265-4ab5-eee9-33f453f2eb68"
      },
      "source": [
        "ModelTrained_path='/content/drive/MyDrive/Model_VietnameseNewsClassification/tfidf_LogisticRegression_model.pkl'\n",
        "VectorizerModel_path='/content/drive/MyDrive/Model_VietnameseNewsClassification/vectorizer_model_tfidf.pkl'\n",
        "predict_news(ModelTrained_path,VectorizerModel_path,texts=texts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Đời sống']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Aw8tdQznUa"
      },
      "source": [
        "Predict with tfid SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKzSD_0qzhmS",
        "outputId": "7099a615-a861-4ebb-ea9e-ce969ead0547"
      },
      "source": [
        "ModelTrained_path='/content/drive/MyDrive/Model_VietnameseNewsClassification/tfidf_SVM_model.pkl'\n",
        "VectorizerModel_path='/content/drive/MyDrive/Model_VietnameseNewsClassification/vectorizer_model_tfidf.pkl'\n",
        "predict_news(ModelTrained_path,VectorizerModel_path,texts=texts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Đời sống']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}